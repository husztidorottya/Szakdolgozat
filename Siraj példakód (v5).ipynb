{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import helpers\n",
    "import operator\n",
    "\n",
    "# GLOBAL CONTANTS\n",
    "PAD = 0\n",
    "EOS = 1\n",
    "character_changing_num = 10\n",
    "max_batches = 3001\n",
    "batches_in_epoch = 20\n",
    "# send 10 sequences into encoder at one time\n",
    "batch_size = 10\n",
    "\n",
    "# x (store encoder inputs [source morphological tags + target morphological tags + source word])\n",
    "source_data = []\n",
    "# y (store decoder expected outputs [source morphological tags + target morphological tags + target word])      \n",
    "target_data = []\n",
    "\n",
    "# character encodings\n",
    "alphabet = dict()\n",
    "\n",
    "# source and target morphological tag encodings\n",
    "morphological_tags = dict()\n",
    "\n",
    "# create (source morphological tags + target morphological tags + source/target word) sequence\n",
    "def create_sequence(data_line_, word_index):\n",
    "    sequence = []\n",
    "    \n",
    "    for i in data_line_[0]:\n",
    "        sequence.append(i)\n",
    "            \n",
    "    for i in data_line_[2]:\n",
    "        sequence.append(i)\n",
    "        \n",
    "    for i in data_line_[word_index]:\n",
    "        sequence.append(i)\n",
    "        \n",
    "    return sequence\n",
    "    \n",
    "\n",
    "# read, split and encode input data\n",
    "with open('data2.tsv','r') as input_file:\n",
    "    # read it line-by-line\n",
    "    for line in input_file:\n",
    "        data_line_ = line.strip('\\n').split('\\t')\n",
    "        \n",
    "        # encode words into vector of ints \n",
    "        for item in range(0,4):         \n",
    "            # contains encoded form of word\n",
    "            coded_word = []\n",
    "            \n",
    "            if item == 1 or item == 3:\n",
    "                # encode source and target word\n",
    "                for character in data_line_[item]:\n",
    "                    index = alphabet.setdefault(character, len(alphabet) + 2)\n",
    "                    coded_word.append(index)\n",
    "            else:\n",
    "                # split morphological tags\n",
    "                tags = data_line_[item].split(',')\n",
    "                \n",
    "                # encode morphological tags\n",
    "                for tag in tags:\n",
    "                    index = morphological_tags.setdefault(tag, len(morphological_tags) + 2)\n",
    "                    coded_word.append(index)\n",
    "            \n",
    "            # store encoded form\n",
    "            data_line_[item] = coded_word\n",
    "        \n",
    "        # store encoder input (source morphological tags + target morphological tags + source word)\n",
    "        source_data.append(create_sequence(data_line_, 1))\n",
    "        \n",
    "        # store decoder expected outputs (source morphological tags + target morphological tags + target word)\n",
    "        target_data.append(create_sequence(data_line_, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A programhoz felhasznált forrásfájl a következőképpen néz ki:\n",
    "\n",
    "    pos=V,mood=IND,def=INDF,tense=PRS,per=1,num=PL\tagyondicsérünk\t\n",
    "    pos=V,mood=IND,def=DEF,tense=PST,per=1,num=PL\tagyondicsértük\n",
    "    pos=V,tense=PRS\türítő\tpos=V,mood=POT\türíthet\n",
    "    pos=V,finite=NFIN\tvitatni\tpos=V,polite=INFM,per=2,num=SG,finite=NFIN\tvitatnod\n",
    "\n",
    "Minden sora egy-egy bemeneti adatot reprezentál (forrás morfológiai tagek + forrás szóalak + cél morfológiai tagek + cél szóalak) formában.\n",
    "\n",
    "Beolvassuk a fájlból soronként, elvégezzük a szükséges feldarabolási lépéseket, majd kódoljuk mind a morfológiai tageket, mind a szóalakokat is számok formájában. Ehhez a már megszokott +1-gyel növelt ABC kódolást használja. A morfológiai tageket páronként kódolja szintén mindig +1-gyel növelt értéktől kezdve: (FONTOS! mivel EOS=1 és PAD=0 ezért a kódolást a 2-es értéktől kezdi)\n",
    "    \n",
    "    pl.: POS=V -> 2-es érték\n",
    "         MOOD=IND -> 3-es érték\n",
    "         \n",
    "A morfológiai tagek kódolt formájából szekvenciát épít és mind a forrás mind a cél tagek szekvenciáját a forrás szóalak szekvenciája elé fűzi, így állítja elő az source_data változóba az encoder bemenetét. \n",
    "             (forrás morfológiai tagek szekvenciája + cél morfológiai tagek szekvenciája + forrás szóalak szekvenciája)\n",
    "             \n",
    "Az előbbihez hasonlóan készíti el a decoder elvárt kimenetét is, amit a target_data változóban tárol:\n",
    "             (forrás morfológiai tagek szekvenciája + cél morfológiai tagek szekvenciája + cél szóalak szekvenciája)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clears the default graph stack and resets the global default graph.\n",
    "tf.reset_default_graph() \n",
    "# initializes a tensorflow session\n",
    "sess = tf.InteractiveSession() \n",
    "\n",
    "max_alphabet = alphabet[max(alphabet.items(), key=operator.itemgetter(1))[0]]\n",
    "max_morphological_tags = morphological_tags[max(morphological_tags.items(), key=operator.itemgetter(1))[0]]\n",
    "\n",
    "# calculate vocab_size (max(alphabet,morphological_tags))\n",
    "vocab_size = max([max_alphabet, max_morphological_tags]) + 1\n",
    "#character length\n",
    "input_embedding_size = 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A vocab_size-ot manuálisan kell kiszámolni, hogy pontosan megállapíthassuk, hogy hány különböző kódolt karakterünk van. (Ennek pontos értékére az embedding miatt van szükség)\n",
    "\n",
    "Mivel az ABC betűit és a morfológiai tag párok kódolt alakját is külön-külön tároltam, ezért meg kell vizsgálnom az ABC betűinél melyik a legnagyobb kódolt érték és melyik a legnagyobb kódolt érték a morfológiai tag-ek kódolt alakjánál. Ezután a két maximum érték közül a nagyobbat kell vennem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# num neurons\n",
    "encoder_hidden_units = 100 \n",
    "# in original paper, they used same number of neurons for both encoder\n",
    "# and decoder, but we use twice as many so decoded output is different, the target value is the original input \n",
    "#in this example\n",
    "decoder_hidden_units = encoder_hidden_units * 2 \n",
    "\n",
    "# input placehodlers\n",
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "# contains the lengths for each of the sequence in the batch, we will pad so all the same\n",
    "# if you don't want to pad, check out dynamic memory networks to input variable length sequences\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "decoder_targets = tf.placeholder(shape=(None, None), dtype=tf.int32, name='decoder_targets')\n",
    "\n",
    "# randomly initialized embedding matrrix that can fit input sequence\n",
    "# used to convert sequences to vectors (embeddings) for both encoder and decoder of the right size\n",
    "# reshaping is a thing, in TF you gotta make sure you tensors are the right shape (num dimensions)\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "# this thing could get huge in a real world application\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)\n",
    "\n",
    "# define encoder\n",
    "encoder_cell = tf.contrib.rnn.LSTMCell(encoder_hidden_units)\n",
    "\n",
    "# define bidirectionel function of encoder (backpropagation)\n",
    "((encoder_fw_outputs,\n",
    "  encoder_bw_outputs),\n",
    " (encoder_fw_final_state,\n",
    "  encoder_bw_final_state)) = (\n",
    "    tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell,\n",
    "                                    cell_bw=encoder_cell,\n",
    "                                    inputs=encoder_inputs_embedded,\n",
    "                                    sequence_length=encoder_inputs_length,\n",
    "                                    dtype=tf.float32, time_major=True)\n",
    "    )\n",
    "\n",
    "#Concatenates tensors along one dimension.\n",
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "#letters h and c are commonly used to denote \"output value\" and \"cell state\". \n",
    "#http://colah.github.io/posts/2015-08-Understanding-LSTMs/ \n",
    "#Those tensors represent combined internal state of the cell, and should be passed together. \n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "#TF Tuple used by LSTM Cells for state_size, zero_state, and output state.\n",
    "encoder_final_state = tf.contrib.rnn.LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h\n",
    ")\n",
    "\n",
    "decoder_cell = tf.contrib.rnn.LSTMCell(decoder_hidden_units)\n",
    "\n",
    "#we could print this, won't need\n",
    "encoder_max_time, batch_size = tf.unstack(tf.shape(encoder_inputs))\n",
    "\n",
    "decoder_lengths = encoder_inputs_length + character_changing_num\n",
    "# +(character_changing_num-1) additional steps, +1 leading <EOS> token for decoder inputs\n",
    "\n",
    "#manually specifying since we are going to implement attention details for the decoder in a sec\n",
    "#weights\n",
    "W = tf.Variable(tf.random_uniform([decoder_hidden_units, vocab_size], -1, 1), dtype=tf.float32)\n",
    "#bias\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)\n",
    "\n",
    "#create padded inputs for the decoder from the word embeddings\n",
    "#were telling the program to test a condition, and trigger an error if the condition is false.\n",
    "assert EOS == 1 and PAD == 0\n",
    "\n",
    "eos_time_slice = tf.ones([batch_size], dtype=tf.int32, name='EOS')\n",
    "pad_time_slice = tf.zeros([batch_size], dtype=tf.int32, name='PAD')\n",
    "\n",
    "#retrieves rows of the params tensor. The behavior is similar to using indexing with arrays in numpy\n",
    "eos_step_embedded = tf.nn.embedding_lookup(embeddings, eos_time_slice)\n",
    "pad_step_embedded = tf.nn.embedding_lookup(embeddings, pad_time_slice)\n",
    "\n",
    "#manually specifying loop function through time - to get initial cell state and input to RNN\n",
    "#normally we'd just use dynamic_rnn, but lets get detailed here with raw_rnn\n",
    "\n",
    "#we define and return these values, no operations occur here\n",
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= decoder_lengths)  # all False at the initial step\n",
    "    #end of sentence\n",
    "    initial_input = eos_step_embedded\n",
    "    #last time steps cell state\n",
    "    initial_cell_state = encoder_final_state\n",
    "    #none\n",
    "    initial_cell_output = None\n",
    "    #none\n",
    "    initial_loop_state = None  # we don't need to pass any additional information\n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)\n",
    "\n",
    "\n",
    "#attention mechanism --choose which previously generated token to pass as input in the next timestep\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "\n",
    "    def get_next_input():\n",
    "        #dot product between previous ouput and weights, then + biases\n",
    "        output_logits = tf.add(tf.matmul(previous_output, W), b)\n",
    "        #Logits simply means that the function operates on the unscaled output of \n",
    "        #earlier layers and that the relative scale to understand the units is linear. \n",
    "        #It means, in particular, the sum of the inputs may not equal 1, that the values are not probabilities \n",
    "        #(you might have an input of 5).\n",
    "        #prediction value at current time step\n",
    "        \n",
    "        #Returns the index with the largest value across axes of a tensor.\n",
    "        prediction = tf.argmax(output_logits, axis=1)\n",
    "        #embed prediction for the next input\n",
    "        next_input = tf.nn.embedding_lookup(embeddings, prediction)\n",
    "        return next_input\n",
    "    \n",
    "    \n",
    "    elements_finished = (time >= decoder_lengths) # this operation produces boolean tensor of [batch_size]\n",
    "                                                  # defining if corresponding sequence has ended\n",
    "\n",
    "    \n",
    "    #Computes the \"logical and\" of elements across dimensions of a tensor.\n",
    "    finished = tf.reduce_all(elements_finished) # -> boolean scalar\n",
    "    #Return either fn1() or fn2() based on the boolean predicate pred.\n",
    "    input = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    \n",
    "    #set previous to current\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "\n",
    "    return (elements_finished, \n",
    "            input,\n",
    "            state,\n",
    "            output,\n",
    "            loop_state)\n",
    "\n",
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:    # time == 0\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "#Creates an RNN specified by RNNCell cell and loop function loop_fn.\n",
    "#This function is a more primitive version of dynamic_rnn that provides more direct access to the \n",
    "#inputs each iteration. It also provides more control over when to start and finish reading the sequence, \n",
    "#and what to emit for the output.\n",
    "#ta = tensor array\n",
    "decoder_outputs_ta, decoder_final_state, _ = tf.nn.raw_rnn(decoder_cell, loop_fn)\n",
    "decoder_outputs = decoder_outputs_ta.stack()\n",
    "\n",
    "decoder_outputs\n",
    "\n",
    "#to convert output to human readable prediction\n",
    "#we will reshape output tensor\n",
    "\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#reduces dimensionality\n",
    "decoder_max_steps, decoder_batch_size, decoder_dim = tf.unstack(tf.shape(decoder_outputs))\n",
    "#flettened output tensor\n",
    "decoder_outputs_flat = tf.reshape(decoder_outputs, (-1, decoder_dim))\n",
    "#pass flattened tensor through decoder\n",
    "decoder_logits_flat = tf.add(tf.matmul(decoder_outputs_flat, W), b)\n",
    "#prediction vals\n",
    "decoder_logits = tf.reshape(decoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))\n",
    "\n",
    "#final prediction\n",
    "decoder_prediction = tf.argmax(decoder_logits, 2)\n",
    "\n",
    "#cross entropy loss\n",
    "#one hot encode the target values so we don't rank just differentiate\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(decoder_targets, depth=vocab_size, dtype=tf.float32),\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "#loss function\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "#train it \n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# send 10 sequences into encoder at one time\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create batches with size of batch_size\n",
    "def create_batches(data, batch_size):\n",
    "    # stores batches\n",
    "    batches = []\n",
    "    # stores last batch beginning index\n",
    "    prev_batch_begin = 0\n",
    "    \n",
    "    for j in range(0, len(data)):\n",
    "        if j % batch_size ==0 and j != 0:\n",
    "            batches.append(data[prev_batch_begin:j])\n",
    "            prev_batch_begin = j\n",
    "            \n",
    "    # put the rest of it in another batch\n",
    "    if prev_batch_begin != j:\n",
    "        batches.append(data[prev_batch_begin:j])\n",
    "        \n",
    "    return batches\n",
    "\n",
    "# encoder inputs devided into batches\n",
    "source_batches = create_batches(source_data, batch_size)\n",
    "\n",
    "# decoder targets devided into batches\n",
    "target_batches = create_batches(target_data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A bemeneti adatokból és az elvárt kimenetekből legyártja a batch_size-nak megfelelő méretű batcheket. \n",
    "\n",
    "Maga a batch szekvenciák kötegét jelenti, hogy egyszerre hány input sort adunk be a rendszerünknek. Ezért fontos, hogy mind az encoder bemenetén, mind a decoder kimenetén azonos méretű batchek legyenek. Emiatt hívjuk meg a source_data és target_data-ra is egyaránt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def next_feed(batch_num, source_batches, target_batches):\n",
    "    # get transpose of source_batches[batch_num]\n",
    "    encoder_inputs_, encoder_input_lengths_ = helpers.batch(source_batches[batch_num])\n",
    "    \n",
    "    # get max input sequence length\n",
    "    max_input_length = max(encoder_input_lengths_)\n",
    "    \n",
    "    # target word is max character_changing_num character longer than source word \n",
    "    # get transpose of target_batches[i] and put an EOF and PAD at the end\n",
    "    decoder_targets_, _ = helpers.batch(\n",
    "            [(sequence) + [EOS] + [PAD] * ((max_input_length + character_changing_num - 1) - len(sequence))  for sequence in target_batches[batch_num]]\n",
    "    )\n",
    "   \n",
    "    return {\n",
    "        encoder_inputs: encoder_inputs_,\n",
    "        encoder_inputs_length: encoder_input_lengths_,\n",
    "        decoder_targets: decoder_targets_,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Mivel a forrás szóalak hossza nem feltétlenül egyezik meg a cél szóalak hosszával, ezért fontos hogy lehetővé tegyük a rendszer számára, hogy további karaktereket fűzhessen az eredetihez. Azt, hogy hány karakterrel lehet hosszabb a képzett szó (cél szó) az character_changing_num változó definiálja.\n",
    "\n",
    "    Ha a character_changing_num = 10 ez azt jelenti, hogy 9 karakterben térhet el az eredeti szóalaktól, mivel a szavak végére +1 karakterként odatesszük az EOF karaktert, hogy jelezzük a decodernek, hogy befejezheti a feldolgozást.\n",
    "    \n",
    "Az ehhez szükséges padding karakterek számának kiszámolásához megkeressük a legnagyobb bemeneti szekvencia hosszát, amit a max_input_length változóban tárolunk el. Ezután a legnagyobb bemeneti szekvencia hosszához hozzáadjuk a (character_changing_num-1) értéket (-1 mert EOF külön hozzáadva) és kivonjuk belőle az aktuális szekvencia hosszát. Ezzel az ettől való eltéréseket 0-val töltjük fel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0\n",
      "  minibatch loss: 3.5781192779541016\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  5  6  7  2  3  8  9  6  7  2  3  4  5  6  7  8  9 10 11 12 13  6\n",
      " 14]\n",
      "    predicted > [ 7  8  7  8  8  7 25  8  0 14 14  1  0 14 12  1  0  6 12  1  0  6 12  1  0\n",
      "  0 33 11 11 13 13 13 10 26 17 17]\n",
      "  sample 2:\n",
      "    input     > [ 2  5  2 10 13 12 16 15 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [40 40 40  3 15  7 18 28  3 28  0  1 28  0 33 11 11 11 16  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 11  2 12 13 14 11 20  8 15  2 15  6  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [40 40  8  8 13 13 13 13 10 17 17 21 29 29  2  0 22 22  0 14 14 20 17 17  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 20\n",
      "  minibatch loss: 2.4980533123016357\n",
      "  sample 1:\n",
      "    input     > [ 2  6 14 11  2  3  4  5  6  7 22  2 14 14  5 25  6  5 31  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  2  4  4  5  6  5  6  5  6  5  6  5  6 13 13 13 13 13 10 26 17 26 17 17\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6 14  2 15  8 12  5 13 14 19 22 17 31  5 25  7 16 15  5 14  0\n",
      "  0]\n",
      "    predicted > [ 2  2  4  2  4  5  6  5  6  5  6  5  6  5  6 13 13 13 13 10 26 26 17 17  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  9  2  3  4  5  6 14 20 23 12  5 10  8  2 10 16 15  5 15 15  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  2  2  4  5  2  5  5  5  5 15  5 15  5 15  5 15  5  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 40\n",
      "  minibatch loss: 2.355062484741211\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  5  6 14  2 15  4 12  5 13  7 20  5  6  4 16 15  5 14  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  2  4  2  2 14  2 14  2 14  7  6  6 22 15 15 15  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  6  7 11  2 12 13  7 11 14  8 15  2 12 15  2  6 29  6 14  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3 12  2 12  2  2 14  2 14  2  7 14  5  6 15 15 15  5  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8  9  6  7  2 12 13 14 11  2  6  6 19 14 15 23 22 15 29 14  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  3 12  2  4  7  2 14  2  7  2 14 14  6  6  6 15 15 15  5  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 60\n",
      "  minibatch loss: 2.348306179046631\n",
      "  sample 1:\n",
      "    input     > [ 2  6  7 11  2 15  4  5  6 14 10 25 19  6 15 19 10 16 15 19  6 13  6 14  0\n",
      "  0  0  0  0  0]\n",
      "    predicted > [ 2  2  6  6  5  6  5  2  7  7  2  3 14 19 19 19  6 19 15 15 23  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  4 12  5 13  7  2  3  8 12  5 13  7 31 19  3 15  2 22 23 22 28  2 15\n",
      "  5 14  0  0  0]\n",
      "    predicted > [ 2  3  8  4 12 12 12  2 13  2  2  7  2  3  7  2  6 19 19 19 15  6 15  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6  7  2 15  4 12  5 13 14 14 19 25  7 19 31 11  6  4 19 25 13\n",
      "  6 14  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  5  2 12  2  2 14  7  2  3  2 19 14 19 19  6 15 19  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 80\n",
      "  minibatch loss: 2.2747740745544434\n",
      "  sample 1:\n",
      "    input     > [ 2 10  2  9 22 19  3 19 22 15 19 15 18 19 15  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  9  2  7  7  7 19 19 19 19 15 19 15 19  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [17 41 14 17 36 14 31 19  3 23 22 22  2 26  5  7 23 10  5 31  0  0  0  0  0]\n",
      "    predicted > [17 17 17 17 14 14 14  7 19 19 19 19 19  6 19 15 19 15  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 11  2  3  8 12  5 13  7 31 19  3 31 29 15  2 15  6  8  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  8 12  2 13  2  8  7  7 19 19 19 19 19 15 19 15 19  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 100\n",
      "  minibatch loss: 2.245232582092285\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13  7  2  3  4  9  6  7 31 19  3  2  7  6 23 15  5 14  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4 12  5  2  2  2  2  2 12  7  7  6 15 15 15 19 15 15 15  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 11  2 15  8 12  5 13  7 14 30 32  5 12  5 22  6  8  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  2 12 11  2  5 13  8 12  5 14 19 10 22 15 15 19 15  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 19 14 17 38 14 31 19  6 15 10 11  3  3 11  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [17 17 17 17 14 14 14 14 19 19  6 22  6 22  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 120\n",
      "  minibatch loss: 2.0039260387420654\n",
      "  sample 1:\n",
      "    input     > [ 2  6  7 11  2 15  4  5  6 14 19 22 18  8  6  6 13  6 14  0  0  0  0  0  0]\n",
      "    predicted > [ 2  6  6  2  2  4  6  6  2 19 19 15 15 15 15  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  4 12  5 13 14  2  3  4  9  6 14 10 25  2 22  2 10 25 15  2  6 23 22]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2  4  5 14 14  5 14 14  6 22 22  6 15 15 15  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6 14  2 15  8  5  6  7 23 15  2  7 15  2 31  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6  2  2  2  4  5  6 15 15 15 15 15 15  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 140\n",
      "  minibatch loss: 1.9793126583099365\n",
      "  sample 1:\n",
      "    input     > [17 40 14 17 34 14 15 29  7  5 31 23 10 10  2 22  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [17 17 14 14 14 14 14 14 19 19  6 22  6  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6  7  2 16  4  5  6  7 14  8 26 12 30 32 23 22 15 29  6 14  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2  2  3  4  5  6  7 19 19 19 19 19 15 15 15  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8  5  6  7  2  3  4 12  5 13  7 20  8 10 10 25  2 27 19 28 15 19  6\n",
      " 11  6 14  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2  2  3  8 12  5 13 19 19 19 19 19 19 19 19 15 15 15  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 160\n",
      "  minibatch loss: 1.9360915422439575\n",
      "  sample 1:\n",
      "    input     > [ 2 16  8 12  5 13  7  2  3  8 12  9 13 14 26 12 30 32 23 22 28 23 15  5 14\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 16  8 12  5 13  7  2  3  8 12 13 13 19 19 19 19 19 15 15 15 15 15  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13 14 11  2 10 11 22 19 10 25 15 19  6 19  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 11 11 11 11 11 11 11 11 10 22 22 15 15 15 15  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4  5  6  7  2 16  4  5  6  7 32 19 10 25 11 22  6 11  6 14  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  4  4  5  6  2  2  4  5  6 14  6 19 22 19 22 15 15 15 15  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 180\n",
      "  minibatch loss: 2.015315532684326\n",
      "  sample 1:\n",
      "    input     > [ 2 12 13  7 11  2  9 14 30 10 15  5 22  6  5 15  5 14  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3 11 12 11  2  2  2  5  6  2  6 15 15  6  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  6  7 11  2  6 14 11 10 15 16 12 21 22  6 13  6 14  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  6 11 11 11 11  6  6  6 22 22  6 22 15  6 15  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4  5  6  7  2 15  8  5  6  7 14 19 20 19 12  6 11  6 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  4  5  6  7  2 15  4  6  6  6  6 22 15  6 15 15  6  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 200\n",
      "  minibatch loss: 1.9200628995895386\n",
      "  sample 1:\n",
      "    input     > [ 2  9  2  3  8  5  6  7 10 25  8  6 15 19 15  8 25 23 22 15  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  2  8  9  6  2  8  9  6 10  2 10 22 22 15 15 15  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 11 32 19 11 26 16 15 19 15 15 19 15 19 14  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2  9  8 19 19 22 22 19 15 15 15  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  6 14 11  2  6  7 11 14  5  6 27 12  5  6 15 23 22  6  5 31  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  6  6 11 11 11  6 11  6 11  6 22 22 15  6 15  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 220\n",
      "  minibatch loss: 1.649033784866333\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4  5  6  7  2  5 31 19  3 16  3 11 12  6 11  6 14  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  4  5  6  7  2 15  5  7  7  6 15 15 15  6  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2  3  8  5  6  7 25  2 14 22  2 15 15  2 15  5 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  9 13  7  2  3  4  9  6  7  7 22 22 15 15 15 15  1  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  6  7 11  2  3  8 12  9 13 14 14 19 12 19 10  6 13  6 14  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  6  7  2  3  8 12 11 13 14 19 19 19 19 19 19 19 19  1  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 240\n",
      "  minibatch loss: 1.9641010761260986\n",
      "  sample 1:\n",
      "    input     > [ 2  6 14 11  2 15  4  5  6  7 27 29 15  6  5 31  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  6 14  2  2 15  5  6  7  6  6 12  6 15  6 14  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8  9  6  7  2 16  4  5  6  7 26 29 32 22  8 14 23 22 15 29 14  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2 16  8  6  6  6 10 22 22 22 25 15 15  6 15 14  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  5  2  3  4  5  6 14 24 28 12  2 27 19 22 18  2 10 25  6 23 22 30  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  3  4 12  6 14 22 22 22 22 25 22 15 15 15  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 260\n",
      "  minibatch loss: 1.528275489807129\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  5 13 14  2 15  4 12  5 13  7 10 26  8  5  6 16 12  5 25  5  7\n",
      "  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2 15  4 12  5 13  7  7  7 22 22 22  5 22 15 15 15 15\n",
      " 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6 14  2  3  4 12  5 13 14 18  2 10  5  3  2 15 15  2 31  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  6 14  2  3  4 12  5 13 14 14 14  2 15 15 15 15 15  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13  7 11  2  3  8  5  6  7 14  5  9 14 23 25 15  2 15  6  5 15  5 14\n",
      "  0  0]\n",
      "    predicted > [ 2 12 13  7  2  3  8  5 13  7  6 14  6 22 22  5  6 15 15 15 14  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 280\n",
      "  minibatch loss: 1.8065614700317383\n",
      "  sample 1:\n",
      "    input     > [ 2 15  8  5  6  7  2 16  4 12  5 13  7  6 19 20 19 25  6 11  6 14  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2  3  4 12  5 13  7 19 19 19 19 19 19 19 19 15 15  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6  7  2  3  8 12  9 13  7 19 22 27  5  3  2  7 15 29  6 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2  3  8 12  9 13  7  7 19 12 19 15 15 15 15 15 15 15 15\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8 12  5 13  7  2 16  4 12  5 13  7 14 21 12 13 22  6 11 25  6 11 15\n",
      " 19 14]\n",
      "    predicted > [ 2 15  8 12  5 13  7  2  3  4 12  5 13 14  7 19 19 19 19 19 15 15 15 15 15\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 300\n",
      "  minibatch loss: 1.6106663942337036\n",
      "  sample 1:\n",
      "    input     > [ 2 16  4 12  5 13  7  2  3  8  9  6  7 20  8 10 10 25  2 27 19 28 15 10 19\n",
      " 15 19 14]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2  3  8 12 19 19 19 10 22 10 22 25 10 15 15 15 15  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  4  5  6 14  2  6 14 11 20  2 14  2 12  6 11 14  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2 14 14 14 14  2  6  6  6  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8 12  5 13  7  2  3  4 12  9 13 14 14 29 22 31  8  6 23 22  6 23 15\n",
      "  5 14  0]\n",
      "    predicted > [ 2 15  8 12  5 13  7  2 15  4 12  5 13 14 14 22 22 22 22 10 22 15 15 15  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 320\n",
      "  minibatch loss: 1.665219783782959\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  5  6  7  2 12 13  7 11 18  8  6 15 13  6 14  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2  3  8 12  5  7  7 19 15 15 15  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8  9  6  7  2 20 31 23 10  5 22 15 29 14  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2 10  2 25 22  2 15 15  5  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8 12  5 13  7  2  6 14 11 12 19  2 22  8 25 23 22  6 23 15  5 14  0]\n",
      "    predicted > [ 2 15  8 12  5 13  7  2 10 11 10 20 25 22 22 25  2 23 15 22  5  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 340\n",
      "  minibatch loss: 1.4415934085845947\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2  3  4 12  9 13  7 15  2  3  2  7  2  6  7 30  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  2  3  4 12  9 13  7  2  7  2  2 15 15 15 15 15 15  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13 14 11  2  3  8 12  5 13  7 15  2 26  2 10 25 15  2  6  5  7  0  0\n",
      "  0]\n",
      "    predicted > [ 2 12 13 14 11  2  3  8 12  9 13  7  2 12  2  2  2  2 15 15 15 15 15 15  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4  5  6  7  2 10 14  8 20 23 22  2 10 10 25 29  6 14  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2 10 10 10 22 10 22 25  2 25  2  6  6  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 360\n",
      "  minibatch loss: 1.7380071878433228\n",
      "  sample 1:\n",
      "    input     > [ 2 12 13 14 11  2  3  8 12  9 13  7 18  2  6  3 10 24 22  4  5 25  6  5  7\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 20 13 14 11  3  3  3  8 12  9 13  7 10  3 22  2 15 15 15 15 15 15  5  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  4  5  6  7  2 16  4  5  6 14 27  5 10 25 15  5  3  2 10 10 29  6 14\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2 16  4  5  6 14 10 10 10  2 25 25  2 25  5 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4  5  6  7  2 10 20 11  6 16 15 10 13  6 14  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2 10  6 10 22 25 22  6  6  1  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 380\n",
      "  minibatch loss: 1.4059293270111084\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13  7  2 16  4  5  6 14 20 19 15 16 15 19  6 11 15 19 14]\n",
      "    predicted > [ 2 15  4 12  5 13  7  2 15  4  5  6 14 14 19 19 19 19  6  6  6  6  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  8  5  6  7  2  3  4 12  9 13 14 27 17 25  6 11  6 14  0  0  0  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2  3  4 12  9 13 14 14 19 15 15 15 15 15  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  5 13 14  2  3  4  9  6  7 14 16  6 23 22 10 25  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2  3  4  9  6 14 14  2  2  2 15 15 15 15 15  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 400\n",
      "  minibatch loss: 1.5254952907562256\n",
      "  sample 1:\n",
      "    input     > [ 2 12 13  7 11  2  3  4 12  9 13  7  8 22 22 19 15  6 19 15 19 14  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 12 13  7 11  2  3  4 12  9 13  7 19 22 22 19 15 15 15 15 15 15  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 11  2 15  8 12  5 13  7  2 25  5  6  5 10 16 15  2  6  8  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 11  2 15  8 12  5 13  7  2 15  2 15  2  2  2  6  6  6  6  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8  5  6  7  2 16  4 12  5 13  7 22  2 26 16 15 28 29 14  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8  5  6  7  2 16  4  5 13  7  7 19 22 22 22 22 22 15 15  6  6  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 420\n",
      "  minibatch loss: 1.3543745279312134\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13 14  2 16  4  5  6  7 31  2 14  5  3  6 23 22  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 16  4  5  6  7 14  2  5 22 22 23  6  6  6 14 14  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 20  2  3  8 12  9 13  7 17 12 25 19  6  7 17  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 20  2  3  8 12  9 13  7 19 19 19 19 19 15 15 15  1  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4 12  5 13  7  2  3  4 12  5 13 14  5 26 19 12 23 22 28  2 15  5 14\n",
      "  0  0]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2  3  4 12  5 13 14 14 22 22 22 22 22  5 15 15  1  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 440\n",
      "  minibatch loss: 1.6357965469360352\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13  7  2  3  8 12  5 13 14  6  4 24 28 15  5 15  5 14  0  0\n",
      "  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2  3  8 12  5 13 14 14  5  5 15 15 15 15  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  4 12  5 13 14  2  3  8  5  6  7 15  8 15 12 23 22  6 23 22  0  0  0\n",
      "  0  0  0  0  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 15  8  5  6  7  8  8  5  6  7 23  6  6 14 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  9 13 14  2  3  4 12  9 13 14  3  4  2 12 31  2 15  5 10 16 15\n",
      "  5 15 15  2  7]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2  3  4 12  9 13 14  2  3  4 12  9  2  2  2  2  2  2\n",
      " 15 15 15 15  5  1  1  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 460\n",
      "  minibatch loss: 1.4685484170913696\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  9  6  7  2  3  4 12  9 13  7 22 19  3  8 15  8 31 23 22 15 29  6\n",
      " 14]\n",
      "    predicted > [ 2  3  4  9  6  7  2  3  4  9 13  7 31 19  3 19  3  8 22 15 15 15 15 15 15\n",
      " 15 15  1  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13 14 11  2  3  4 12  9 13  7 25 24 25  6  5  7  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 12 13 14  2  3  4 12  9 13 14  9 12 12 15 15 15 15  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  5 13  7  2 20  6  4 21  3 15 21 14  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2  9 15 15 15 15 15 15  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 480\n",
      "  minibatch loss: 1.3172683715820312\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2 15  4  5  6  7 20 11 15 30 25  2  6  7 30  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 20  2 15  4  5  6  7 20  2  2  2  2  6  6  6  6  1  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13 14 11  2 16  8  5  6  7  8  3  2 25  5 22  6  5  7  0  0  0  0  0]\n",
      "    predicted > [ 2 12 13 14 11  2 16  8  5  6  7  7  5  2 25  5  2 25  5  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6  7  2  5 22 19 27  5  3 22  2 22 15 29  6 14  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 10  6 22 22 22 25 22 15 15 15  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 500\n",
      "  minibatch loss: 1.2891775369644165\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13  7  2 16  8 12  5 13  7 19 22 10  5  7  5 12  6 23 15  5\n",
      " 14]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2  3  8 12  5 13  7  7 19  3  5 23 22 23 15 15 15 14\n",
      " 14 14  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  5  2 15  4 12  5 13  7 14 11 26 20  8 10 19 22 17  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  2 15  4 12  5 13  7 13 14 11 19 19 19 15 19 15 19 15  1  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  9 13 14  2  3  4  9  6 14 14  8 22 11 22 19  3 19 25 15 19  7\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2  3  4  9  6 14 14 14 19 19 15 15 15 15 15 15  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 520\n",
      "  minibatch loss: 1.4782965183258057\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4  5  6 14  2 16  4 12  5 13  7 22 19  5 22 15  2  6 11 14  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2 15  4 12  5 13  7 19 19 22 22 22 22 22 22 23  6  1  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  9 13  7  2 16  4  5  6 14  2 29 15  5 31  2 15  8 25 23 22 15\n",
      " 23 15  5 14  0  0  0]\n",
      "    predicted > [ 2  3  8 12  9 13  7  2 16  4  5  6 14  2 20  2 25  2  2 25 22  6  6  6  6\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4  5  6 14  2 15  8 12  5 13  7 27 19 22 10 25 19 12 19 22  6 11 14\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2 15  4 12  5 13  7 19 19 19 19 19 22 19 22 15 19 15  6\n",
      "  6 14  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 540\n",
      "  minibatch loss: 1.3632235527038574\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4  5  6 14  2  3  8  9  6  7 31 19 31  5 12  8 25 23 22  6 11 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2  3  8  9  6  7 31 19 31 31  3  8 12 15 15 15 15 15 14\n",
      " 14  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13 14  2 12 13  7 11 19 22 32  5  9 10 23 15  5  7  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2 12 13  7 31 19 12 31 22 22 23 23 15 15 15 15  5  5\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4 12  5 13 14  2  3  8 12  5 13 14 25 10  8  6  7 19 22  4 19 25  6\n",
      " 11 22]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2  3  8 12  5 13 14 10  8  8 25 25 10 25 22 19 15 15\n",
      " 15  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 560\n",
      "  minibatch loss: 1.3528807163238525\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2 11 22 30  3  2  6  7 30  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 20  2 20  2 20  2 22 15 15  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13  7  2 15  8  5  6  7 32  5  9 10 23 15 28 23 15  5 14  0]\n",
      "    predicted > [ 2  3  8 12  5 13  7  2 15  8  5  6  7 15  2  5 23  5  6 29 29  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6 14  2 16  8 12  5 13  7 14 21 12 21 25 15 19 31  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6 14  2 16  8 12  5 13  7 10 10 19 12 10 25 15 15 15 15  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 580\n",
      "  minibatch loss: 1.3528188467025757\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13 14  2 20 27 33 12 11 10 25 19 22 10 25  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2 11 11 11 19 19 19 25 19 25 19  6  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  5 13  7  2 16  8 12  5 13  7 22  2 14 14  5 25 15  5 14  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2 16  4 12  5 13  7 25 10  2 25  5  5 22  5  1  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4 12  5 13  7  2 15  4  5  6 14 15  8 26 26 19 22 28 19 15 19 14  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2 15  4  5  6 14  8 19 19 19 19  6  6 19  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 600\n",
      "  minibatch loss: 1.4737701416015625\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 11 26 23  9  5 22 15  2 15  5 14  0  0  0  0  0  0\n",
      "  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2  2  5 22 15  2 15 15 15 15  1  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13 14  2 15  8 12  5 13  7  8  6  3  2 15  5  7  0  0  0  0\n",
      "  0  0  0  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2 16  8 12  5 13  7 15  8  5 23 23 23 23 23 15 14 14\n",
      " 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 30  7 17 36  7 14 29 12  7  5 14  6 23 22  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0]\n",
      "    predicted > [17 17  7 17  7  7  2 12  5 23 14  5  5  6 14  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 620\n",
      "  minibatch loss: 1.4545546770095825\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2 12 13  7 11 32  5 31 32  2 12  7 16 12  5 25  2  6  7 30  0  0  0]\n",
      "    predicted > [ 2 12 13 14 11  2 12 11 12 11  8  2  8  5  6  5  6  5 23  6  5  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [17 27 14 17 26 14 20 11  3 13 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [17 14 17 14 14 14 12 12 19 19  6  6  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  9  2  3  4  9  6 14 14  8  2 22  2 14 16 15  5 15 15  0  0  0  0  0  0]\n",
      "    predicted > [ 2  9  2  3  4  9  6 14 14  2  2  2  2 15 15 15 15 15  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 640\n",
      "  minibatch loss: 1.170390009880066\n",
      "  sample 1:\n",
      "    input     > [ 2 16  8  5  6  7  2 15  4  5  6 14 12 21  3 25 16 15 10 13 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 16  8  5  6  7  2 15  4  5  6 14 14 15 10 15 15 15 19  6 19  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 10  2  3  8 12  9 13  7 27 19 15  8 10  8 25 23 22 18  2 15  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 10  2  3  8 12  9 13  7 10 10 10  8 22  2 15 23 15 15 15 15 15  1  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6  7  2  3  8 12  9 13  7 27 30 14 29 10 25 23 22 15 29  6 14\n",
      "  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2  3  8 12  9 13  7 10 25 12 10 23 23 23 23 15 15  5  5\n",
      "  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 660\n",
      "  minibatch loss: 1.259274959564209\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4  5  6 14  2 20 27 13 12  7 19 15  6 11 14  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2 12 11 19 19 19 19 19 15 15 19  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13 14 11  2  3  4 12  9 13  7 31 19  3 10 25 23 31 22 23 22  6  5  7]\n",
      "    predicted > [ 2 12 13 14 11  2  3  4 12  9 13  7 31 19  3 31 22 23 15 15 15 15 15 15 15\n",
      "  5  1  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6  7  2 10 14 16 10 11 12 13  6 14  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2 10 10 10 10 12 10 15 15  1  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 680\n",
      "  minibatch loss: 1.2868424654006958\n",
      "  sample 1:\n",
      "    input     > [17 23 14 17 39  7 15 21 12 25 10 19 15  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [17 17 14 17  7 23 15 15 23 15 15 19 14  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8  9  6  7  2 16  8  5  6  7 19 22 20 23  3 15 29 14  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2 16  8  5  6  7 22 22 22 23 29 29 14 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6  7  2 15  8 12  5 13  7 31 23  6  3  5 12  5 22 29  6 14  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2 16  8 12  5 13  7 31  5  5  3  5  5 23  5 23 23  6  5\n",
      " 14 14  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 700\n",
      "  minibatch loss: 1.3685251474380493\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8  9  6  7  2 16  4  5  6 14  5 26 26  5  6 23 22 15 29 14  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2 16  4  5  6 14  5  5  5  5 23 22  6  6 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13 14  2  3  4 12  9 13 14 13 15 21  7  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2  3  4 12  9 13 14 15 15 15 15 15 19 19  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  9  2 15  4 12  5 13  7 31  2  3 23 25  5 15 15  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  9  2 15  4 12  5 13  7 15  2  5 23 15 15 15 15  5 14  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 720\n",
      "  minibatch loss: 1.1863348484039307\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  9  6  7  2  3  4 12  5 13 14 15 21  6 14 12 19 15 19 15 15 13  6\n",
      " 14]\n",
      "    predicted > [ 2  3  4  9  6  7  2  3  4 12  5 13 14 14 14 12 19 22 19 15 15 15  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  4 12  5 13  7  2 15  8  5  6  7 14  8 15  2  3  2  7 28  2 15  5 14\n",
      "  0]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2 15  8  5  6  7  2  3  3  2  2 15 15 15  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13  7 11  2  3  8 12  9 13 14 14  8 10 25 19  6 20 19  7  6 19 15 19\n",
      " 14]\n",
      "    predicted > [ 2 12 13  7 11  2  3  8 12  9 13 14 14 10 14 10 19 19 19 19 15  7  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 740\n",
      "  minibatch loss: 1.3795820474624634\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13 14  2 15  4  5  6 14 14  2 26  9 10  5 22 10 25  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2 15  4  5  6 14 14 10  8 12 12 15 22 22  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  9  2 16  4 12  5 13  7 27 19 22  7  5 32  5 15 15  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 16  2 16  4 12  5 13  7 27 19 22 22 22 22 15 15 15  5 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  5 13 14  2  3  4  5  6 14 14 11 26 20  8 10 19 22 10 25  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2  3  4  5  6 14 14  8 14 20 19 16 15 19 15  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 760\n",
      "  minibatch loss: 1.1236491203308105\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  9 13 14  2 12 13 14 11 19 22 11 16 12 15  2  7  0  0  0  0  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2 12 13 14 11 11 12 12 12  6 22  6 22  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 10  2 16  8 12  5 13  7 12 19 10 25 14 16 12  5 25 18  2 15  0  0  0  0]\n",
      "    predicted > [ 2 16  2 16  8 12  5 13  7 10 12 10 25 10 25 25 23 23 23 15 15 15  5  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6  7  2  6  7 11  3  4 24 12 15 29  6 14  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2  6  7 11  5  6  7 12 29 29 29 14  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 780\n",
      "  minibatch loss: 1.2723838090896606\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  5 13  7  2  6  7 11 32  8 25  5  6  4 16 15 28 23 15  5 14  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13  7  2  6  7 11 19  6  7  2  2  2  6  6  6  6 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 16  8 12  5 13  7 31 19  3  3  4  8 22 14  5 22 15\n",
      "  2 15  5 14]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2 16  8 12  5 13  7 19 19  3  2  2  2  2 15 15 15 15\n",
      " 15 14  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6  7  2 16  8  5  6  7 14  2 22  2 26 23 22 29  6 14  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2 16  8  5  6  7 14  2  2  2  2 25  6 29 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 800\n",
      "  minibatch loss: 1.1330796480178833\n",
      "  sample 1:\n",
      "    input     > [ 2 16  4  5  6  7  2  3  8 12  5 13  7 18 33 15 10 13  6 14  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2  3  8 12  5 13  7 15 19 15 15 15 15 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 10  2 15  8 12  5 13  7 14 21 26 18 19 15  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 10  2 15  8 12  5 13  7 10 19 19 15 19  6  6 14  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  6  7 11  2 16  8 12  5 13  7 32 22  5  3  5 22  6 29  6 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  6  7 11  2 16  8 12  5 13  7 32  5  3  5 22 22 22 23  5 14 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 820\n",
      "  minibatch loss: 1.2999306917190552\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  5  6 14  2  3  4  9  6  7 19 12 19  7 31 11  6  4 19 25 19 14  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  3  4  9  6  7 31 19 19 19 19 19 19 19 19 19 15 15 14\n",
      " 14  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6  7  2 15  8 12  5 13  7 25 10  8  6  7 19 22  4 19 25 15 13\n",
      "  6 14  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 15  8 12  5 13  7 19 19  7 25 25 25 25 19 25 15 19 15\n",
      "  6 14 14  1  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 39  7 17 41 14 32 17 20 16 15 11 10 19  8 15 19 14  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [17 40  7 17  7 17 15 15 15 16 15 19  6 19  6 14  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 840\n",
      "  minibatch loss: 1.1609476804733276\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13  7  2 15  4  5  6  7  7  8  2  3  6  5 10 25 15  8 25 23\n",
      " 22 15  5 14  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2 15  4  5  6  7  7 25  8  8  6  5  6 25 25 25  6 23\n",
      "  6  6 14 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2  3  4 12  5 13  7 27 19 12 15 17 15 22 19  6 16 15\n",
      " 19 15 15 19 15 19 14]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2  3  4 12  5 13  7 15 19 19 12 19 22 19 15 15 19 15\n",
      " 19 15 14  1  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  6 14 11  2 16  8  5  6  7 20  8 10 19 22  6 19 31  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  6 14 11  2 16  8  5  6  7  8  8 19 25 19 28 14 14  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 860\n",
      "  minibatch loss: 1.0341885089874268\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  9 13 14  2  9 32  5 31 32  2 12  7 16 12  5 25 15  2  7  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2  6 14 11 12  2 12  2  2  2  2  5  5 15  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6 14  2  3  4 12  9 13  7 19 22 20 19 12 19 14  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  3  4 12  9 13  7 19 19 19 19 15 19 15 15 15 19  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  9 13 14  2 16  8 12  5 13  7 19 22  2  7 15  2  7  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2 16  8 12  5 13  7 22 22 22 28 28 28 15 15 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 880\n",
      "  minibatch loss: 1.1670007705688477\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8  9  6  7  2 15  8 12  5 13  7 22  2 15  5 22  3  2 15 15 29 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2 15  8 12  5 13  7 15  2 15  2 15 15 15 15 15  5  5 14\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6 14  2  3  4 12  9 13  7  2 12  2 15  5 14  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  3  4 12  9 13  7  2  2  2 15 15 15 15  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13  7 11  2  3  8  9  6  7 21 10 10 25 19 12  2 14  6  5 15  5 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2 12 13  7 11  2  3  8  9  6  7 10 10 10 25 16 16 15 15 15 15 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 900\n",
      "  minibatch loss: 1.1388815641403198\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13 14  2 16  8 12  5 13  7 26  2 12 14  5 22  6 23 22  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 16  8 12  5 13  7 26  5 12 12 23 23 23 23 15  5 14\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 16  8 12  5 13  7 14 11  6  4 19 25 15 19 15 15 19\n",
      " 15 19 14  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2 16  8 12  5 13  7 14 19 19 19 19 25 19 19 15 19 15\n",
      " 14  1  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  5 13 14  2  3  4 12  9 13 14 15 12  2  6 10 25 26 22  2  6 15\n",
      " 23 22 10 25]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2  3  4 12  9 13 14 20  2  8  2  8  2  8  2 25 25 15\n",
      " 15 15 15 15  5  1  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 920\n",
      "  minibatch loss: 1.2253179550170898\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13 14  2 16  4  5  6 14 31 19  3 14 21 20 19 25  6 11 22  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 16  4  5  6 14 14 21 21 21 19 19 10 19 19 15 14  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  5 13  7  2 10 26  8 10 25 14 23 22 15  5 14  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2 10 10 10 10 10 23 23 18 15 15  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 11  2 10 31 19  3 14 21 20 19 25  6  8  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 11  2 10 10 10 19 19 19 25 19 25 15 15  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 940\n",
      "  minibatch loss: 1.1677231788635254\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4 12  5 13 14  2 11 22 19  5 22 15  2  6 23 22  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 11 22 22 22 22  6  6  6  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13  7  2 15  8  5  6  7  6  4 29  3 15  2 15 28 23 15  5 14\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  5 13  7  2 15  8  5  6  7 31 19  6 15 16 15  6  6  6  6  1 14\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4  5  6 14  2 16  4  5  6  7 10 25 19  6  6  4 19 25  6 11 14  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2 16  4  5  6  7 14 19  6 10 25 19  6  6  6  6 14 14  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 960\n",
      "  minibatch loss: 0.9328374266624451\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  9 13 14  2 16  4 12  5 13  7 20  2 12 12 15  2  7  0  0  0  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2 16  4 12  5 13  7 12 12 12 12  2  2  7 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 16  4  5  6  7 15 19 12 31 19 22 15 19 15 19 14  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2 16  4  5  6  7 27 19 19 19 19 19 11 15 19 14 14  1\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13 14 11  2  3  8  9  6  7 19 22 18  8  6  6 19  7  0  0  0  0  0  0]\n",
      "    predicted > [ 2 12 13 14 11  2  3  8  9  6  7 32 19 19 22 15 15 15 15 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 980\n",
      "  minibatch loss: 1.0912089347839355\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  9  6  7  2 16  4  5  6  7 10 30 20 23 12  5  3 15 29  6 14  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 16  4  5  6  7 14 23 12 12 23 23 22 23 29 14  1  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  9  2  6 14 11 31 19  3 14 21 10 25 21  6 15  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  6 14 11  2  9 14 11 31 19 25 19 25 19 19  1  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 20  2 16  8 12  5 13  7 27 19  6 19  6  7 17  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 20  2 16  8 12  5 13  7 19 19 19 19 19 28 14  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1000\n",
      "  minibatch loss: 0.9820376634597778\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8  9  6  7  2 15  8 12  5 13  7 19 22 12  2  3  2  7 15  2 15 15 29\n",
      " 14]\n",
      "    predicted > [ 2  3  8  9  6  7  2 15  8 12  5 13  7 19 19  3  2  2  2  2 15 15 15 15 15\n",
      "  5  5 14  1  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6  7  2  3  4 12  9 13 14 20  8  3  2 10 25 15  2 22 29  6 14\n",
      "  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2  3  4 12  9 13 14 20 10  2  2 10  2 15 16 15 15 15 15\n",
      " 15  1  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  5 13 14  2 16  4  5  6 14 14  5  6 25 19 12 20 23 22 10 25  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2 16  4  5  6 14 14  5  6 14 20 22 22 25 22 25 14 14\n",
      "  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1020\n",
      "  minibatch loss: 1.072452187538147\n",
      "  sample 1:\n",
      "    input     > [ 2  9  2 10 26  8 10  8 22 15  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  9  2 10  8 10  8 15 15 15  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  9 13 14  2 10 19 22 14 11 10 25 16 15 19 15 15 19  7  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2 10 10 19 19 19 25 15 15 15 15 15 15  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  9 13 14  2  3  4  9  6  7 15 23 22  2 22 15 23 22  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13 14  2  3  4  9  6  7 22 23 22 15 15 15 15 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1040\n",
      "  minibatch loss: 1.111146330833435\n",
      "  sample 1:\n",
      "    input     > [ 2 16  4  5  6  7  2  3  4 12  5 13  7 20  2 10  2 22 28 29  6 14  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2  3  4 12  5 13  7 20  2  2  2 25 15 15  5 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 10  2 20 31 29 15  2 15 18  2 15  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 10  2 20 15 23 15 15  2  6  6  6  1  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6 14  2 15  8  5  6  7 15  2 22 22 30 25  5 14  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2 15  8  5  6  7 22 22 22 22 22  6  6  6 14  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1060\n",
      "  minibatch loss: 0.9578656554222107\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 15  4  5  6  7  9 10  8 12  8 25 19 22 15 19 15 19\n",
      " 14  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2 15  4  5  6  7 20  8  8 10 25 15 19  6  6  6  6 14\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13  7  2 20 29  6 15  2 15 28 23 15  5 14  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13  7  2 20 20  2 15  2 15  2 15  6  6  1  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8  5  6  7  2 12 13  7 11 20  8 10 19 22  6 11  6 14  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2 12 13  7 11 20 19 25 19  6  6  6 19 15 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1080\n",
      "  minibatch loss: 1.2014786005020142\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13 14  2 11 25  2 20  2 12 15 23 22  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13 14  2 20 11 20  2  2 25  6  6 30  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6 14  2 20 22 19 22 15 19 31  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6 14  2 20 22 19 19 15 19 15  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4  5  6  7  2  3  8  9  6  7 27 19 22  2  7 28 29  6 14  0  0  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2  3  8  9  6  7 27 19 22 22 22 28 29 29 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1100\n",
      "  minibatch loss: 1.007054090499878\n",
      "  sample 1:\n",
      "    input     > [ 2  5  2 15  4  5  6  7 31 19  3 10 25 23 31  5 25 30  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  5  2 15  4  5  6  7 31 19  3 31 31 10 25 23 23 23  6  6 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13  7 11  2 20 32  5 31 32 23 25  6  5 15  5 14  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 12 13  7 11  2 11 32 10 32 25 23  5  5  5 15  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6 14  2 12 13  7 11 18  2 12 31  5  6  8 25 23 22  5 14  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2 12 13  7 11 31 19 12 26  2  2 12 12 23 23  5  5 15  5\n",
      "  5  1  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1120\n",
      "  minibatch loss: 1.0427883863449097\n",
      "  sample 1:\n",
      "    input     > [ 2 11  2  3  4 12  5 13 14 10 25  2 26 26  2  6  5 25  6  8  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 11  2  3  4 12  5 13 14 10 25  5  2  5 25  5 25  5 15  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  8 12  5 13 14  2  3  4  5  6  7 14  8 15  2 22 23 22  6 23  7  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  8 12  5 13 14  2  3  4  5  6  7 15  2 22 22 22 22 29  6  6 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6 14  2 16  8 12  5 13  7 22 19 27 19 28 19 25 19 14  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2 16  8 12  5 13  7 27 19 22 19 22 19 22 19 19 19 14  1\n",
      "  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1140\n",
      "  minibatch loss: 1.1102789640426636\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  9 13 14  2  3  8 12  5 13 14 14 19 20 19 12 15 19  7  0  0  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2  3  8 12  5 13 14 14 19 19 19  7  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6 14  2  3  4 12  9 13 14 27 19 22 15 21 22 15 21 14  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  3  4 12  9 13 14 22 19 22 15 15 15 15 15 15  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6 14  2  5  2 25  5  6  5 10 16 15  5 14  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  5  5 10  5 25  5 25 30  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1160\n",
      "  minibatch loss: 0.8515259623527527\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 16  4  5  6  7 27  2 12  2  3 15  2 15  5 14  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2 16  4  5  6  7 27  2 12 12  2 28 29 14 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13  7 11  2  3  8  9  6  7  9 10 21  6  3 19 15  6 19 15 19 14  0  0]\n",
      "    predicted > [ 2 12 13  7 11  2  3  8  9  6  7  9 19 19 10 15 15 15 15 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4 12  5 13 14  2 15  8 12  5 13  7 32 19 12 24  3  6 23 22  0  0  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 15  8 12  5 13  7 32 19  6  6 23 23 23 15 15 14 14\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1180\n",
      "  minibatch loss: 1.0085163116455078\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13 14  2 15  4 12  5 13  7 14  5  6 10 15  2 15 23 22 10 25\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2 15  4 12  5 13  7 15  2  2  2  2 10 25 22 15 23 15\n",
      " 15 14 14  1  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  8 12  5 13 14  2  3  4  5  6 14 19 22  6 11 25  6 11  7  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 15  8 12  5 13 14  2  3  4  5  6 14 19 19 19 25 25 25 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 22 14 17 19 14  2 12  2 32  5  7  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [17 14 14 17 14 14  2 12 12  2 22  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1200\n",
      "  minibatch loss: 1.007680892944336\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2  3  4 12  9 13 14 20 19 12 32 29 20 23 22  2  6  7 30  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 20  2  3  4 12  9 13 14 20 12 22 22  2  2 12 12 23 22 15  7  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6 14  2 12 13  7 11 25  2  3  4 20 23 22 15  2 31  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  6 14  2 12 13  7 11  2 22  2  2  2  2 22 25 15 15 15  5 14  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  6 14 11  2 16  4  5  6 14  6  4 24 28 15  2  6  5 31  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  6 14 11  2 16  4  5  6 14 18  4  4  4 29 29  6 14  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1220\n",
      "  minibatch loss: 1.0034871101379395\n",
      "  sample 1:\n",
      "    input     > [ 2 15  8 12  5 13 14  2 15  8  5  6  7 15  5 28  6 23  7  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  8 12  5 13 14  2 15  8  5  6  7  7  6  6  6  6 14  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  5 13 14  2 16  4  5  6  7 31 11 12  3 19 10 16 15 19 10 25  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2 16  4  5  6  7 31 19  3 12 31 10 10 25 15  6 14 14\n",
      "  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6  7  2 16  4  5  6  7  9 11 22  5 25 15 29  6 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 16  4  5  6  7  7 25  5 25 22 29 29 14 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1240\n",
      "  minibatch loss: 0.8254029750823975\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2 15  4 12  5 13 14 14 21 26 19  6  7 17  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 20  2 15  4 12  5 13 14 14 21 21  6 11 11  1  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  9 13  7  2  3  4  9  6  7 31 19 12 15 11 15 19 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13  7  2  3  4  9  6  7 31 19 12 12 19 15 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8 12  5 13 14  2  3  8  9  6  7 14 21 26  6 11  7  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  8 12  5 13 14  2  3  8  9  6  7 14 21 13 15 13 13  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1260\n",
      "  minibatch loss: 0.8543308973312378\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8  9  6  7  2  6  7 11 19 22 17 23 22 22 16 15  5 15 15 29 14  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2  6  7 11 22 22 22 22 22 22 15 15 15  6  6 14 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  9 13  7  2  3  4  9  6  7 19 22 18  8 15 15 11 15 19 14  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13  7  2  3  4  9  6  7 22 19 15 15 15 15 15 13  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  9 13 14  2  3  8 12  5 13 14 29 12  2 22 15  2  7  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2  3  8 12  5 13 14 27  2  2  7 23  7  7  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1280\n",
      "  minibatch loss: 0.9258642196655273\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13  7  2  3  4 12  5 13  7 20  8  6  6  4  5  3 15  2 15  5\n",
      " 14  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2  3  4 12  5 13  7  6  6  5  5 15 15 15 15 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6  7  2  3  8  9  6  7 27  5 12 12  2 22 15 29  6 14  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2  3  8  9  6  7 27 12 12 12 12 29 29 29  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13  7 11  2 15  4 12  5 13 14 27 19 22 18  2 10 25  6 23 22  6  5 15\n",
      "  5 14]\n",
      "    predicted > [ 2 12 13  7 11  2 15  4 12  5 13 14 27 22 22 22  2  2  2 25  6 23 22  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1300\n",
      "  minibatch loss: 0.9004606604576111\n",
      "  sample 1:\n",
      "    input     > [ 2 12 13  7 11  2 15  8  5  6  7 27  2 14  2 10 25 15  2  6  5 15  5 14  0\n",
      "  0]\n",
      "    predicted > [ 2 12 13  7 11  2 15  8  5  6  7 20  2  2  2  2  2  2 25  6  6  6 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  8  5  6  7  2 11 22 19  8  6 15 19  6 11  6 14  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2 11 15 19 19 22  6  6  6  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 10  2 16  4  5  6  7 14  2 26 18  2 15  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 10  2 16  4  5  6 14  2  2  2 29 29 14  1  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1320\n",
      "  minibatch loss: 0.9784969091415405\n",
      "  sample 1:\n",
      "    input     > [ 2 16  4 12  5 13  7  2  3  4  5  6 14 14  8 23 32 12 23  6  7 16 15 10  2\n",
      " 15  5 14]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2  3  4  5  6 14 14  8 12 23 23 23 23 16 15 15 15 29\n",
      " 14  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  4 12  5 13  7  2  6  7 11 31 19  3 19 31 22 16 15 10 19 15 19 14  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2  6  7 11 31 19  3 15 19 19 15 15 15  6  6  6 14  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  5 13 14  2 20 20  8 15  2 15  5  7  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2 20 20  8 20 15  6  6  7  7  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1340\n",
      "  minibatch loss: 0.9738166332244873\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13 14  2  3  8 12  5 13  7 11 22 19 10 25 15 19 10 25  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2  3  8 12  5 13  7 20 19 22 25 25 25 22 19 15 15 14\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  5  2  3  4 12  9 13 14 20 11  7 17  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  5  2  3  4 12  9 13 14 20 19 15 15 15 19  7  1  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  9 13  7  2 16  8 12  5 13  7 22 19 12  5 31 32  5 22 15 23 15\n",
      "  5 14]\n",
      "    predicted > [ 2  3  8 12  9 13  7  2 16  8 12  5 13  7 31 19  5 31  5 31 22 22 23 23 15\n",
      "  5  5  1  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1360\n",
      "  minibatch loss: 0.8895914554595947\n",
      "  sample 1:\n",
      "    input     > [ 2 15  8  5  6  7  2 16  4 12  5 13  7 32 33 20 21 22  6 11  6 14  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2 16  4 12  5 13  7 32 19 11 22 25 15 15 15 19 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8  5  6  7  2 20 31 19  3 14  5 26  2 10 25 15 28 29 14  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  8  5  6  7  2 20 31 19  3 26  2  2  2 15  2 15  2  6  6  1  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6 14  2 12 13  7 11  3  4  2 22 23 25 15  2 31  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4  9  6 14  2 12 13  7 11  2  2  4 22  2  2 15 15  5  5 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1380\n",
      "  minibatch loss: 0.8434423208236694\n",
      "  sample 1:\n",
      "    input     > [ 2 16  8 12  5 13  7  2  6  7 11  7  2  9  5 22 28 23 15  5 14  0  0]\n",
      "    predicted > [ 2 16  8 12  5 13  7  2  6  7 11  7  2  5  5  6  6 29  6  6 14  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  6  7 11  2  5 15 23 20  8 12 23  6  4 16 15  2  6 29  6 14  0  0]\n",
      "    predicted > [ 2  6  7 11  2 15 15 15 15 23 15 16 16 16 15  6  6  6  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 10  2  3  4  5  6  7 31 19  3 32  5  9 10 23 15 18  2 15  0  0  0]\n",
      "    predicted > [ 2 10  2  3  4  5  6  7 31 19  3 31 10 10 15 15 29 29  6 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1400\n",
      "  minibatch loss: 0.9717031121253967\n",
      "  sample 1:\n",
      "    input     > [ 2 20  2  3  8 12  5 13  7 15  2  6 23  9 10  5 22  2  6  7 30  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 20  2  3  8 12  5 13  7  2  5  2  3  5 10  5 23 15 15 15 14 14  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  5  2 15  4 12  5 13 14  7 19  3 19  6 19 12 23 22 30  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  5  2 15  4 12  5 13  7 27 19 19 19 19 19  7  6  6 23  6 14 14  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8  5  6  7  2  3  4 12  5 13  7 26  8 23 22  6 23  6 14  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2  3  4 12  5 13  7 26 23 22 28 28 15 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1420\n",
      "  minibatch loss: 0.9180574417114258\n",
      "  sample 1:\n",
      "    input     > [17 29  7 17 38 14 18  2 22 31  2 25  5 14  8  3  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [17 27  7 17 23 14  2  2 22 23  5  5 23  5  1  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  8 12  5 13  7  2  3  4  5  6 14 10  2 28  6 23 22 28 23 15  5 14  0\n",
      "  0]\n",
      "    predicted > [ 2 16  8 12  5 13  7  2  3  4  5  6 14 18  2  2 23 10 10  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 20  2 15  4 12  5 13 14 27 24 28  7  5  3 23 22  2  6  7 30  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 20  2 15  4 12  5 13 14 27 27  3 23 23 22 22 23 23  5  5  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1440\n",
      "  minibatch loss: 0.9066427946090698\n",
      "  sample 1:\n",
      "    input     > [ 2 15  4  5  6 14  2 12 13 14 11 27 19 22 24 28 16 15  2  6 11 14  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2 12 13 14 11 27 19 22 22 22  6  6  6 15  7  7  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6 14  2  3  4  5  6  7 26 12 30 32 23 22  5 14  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2  3  4  5  6  7 32  8 12 12 23 22 22 29 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  9  2  3  8 12  5 13  7 14  8 28 19 22 21 22 15  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  9  2  3  8 12  5 13  7 14  8 22 22 22 22 22 28 15 14 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1460\n",
      "  minibatch loss: 0.8997472524642944\n",
      "  sample 1:\n",
      "    input     > [ 2  6 14 11  2 11 10 25 16  6  5 31  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  6 14 11  2 11 25 25 16 15 15 15  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  9  6  7  2  3  4  9  6 14 15 24 22 11 22 15 13  6 14  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2  3  4  9  6 14 11 22 22 22 15 15 15 15 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 10  2 15  4  5  6  7 31  5 25  7 16 15 18  2 15  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 10  2 15  4  5  6  7 31  4 16 16 16 15  6  6  6 14 14  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1480\n",
      "  minibatch loss: 0.8373379111289978\n",
      "  sample 1:\n",
      "    input     > [ 2 10  2  3  8 12  9 13  7 14 11 26 20  8 10 19 22 18 19 15  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 10  2  3  8 12  9 13  7 14 11  8  8  8  8 25 25 22 15 15 19 14 14  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  6  7 11  2  9 15  5 32  5 12  5 25  6 29  6 14  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  6  7 11  2  5  5  5  5  5  5  5 22  6  8  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4 12  5 13  7  2 16  8  5  6  7 14 19 12 16 15 10 19 15 19 14  0  0\n",
      "  0]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2 16  8  5  6  7 14 19 16 16 10 10 19 14 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1500\n",
      "  minibatch loss: 0.8356648683547974\n",
      "  sample 1:\n",
      "    input     > [ 2 15  8  5  6  7  2 16  4  5  6  7 20 19 25 19 15  6 11  6 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  8  5  6  7  2 16  4  5  6  7 20 19 20 19 19 15 13 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  4  5  6 14  2  3  4  5  6  7 22  2 26 16 15  2  6 11 14  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2  3  4  5  6  7 22  2  2 16 15 15 15 14  1  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13 14 11  2  5 19 22 20  5  6 10 25  5 22  6  5  7  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2 12 13 14 11  2  5  2 10 25 25  5 22  5 25  5 15 15  1  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1520\n",
      "  minibatch loss: 0.9184094667434692\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8  9  6  7  2  3  4 12  5 13 14 14 30 32  5 12  5 22 15 29 14  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8  9  6  7  2  3  4 12  5 13 14 14  5 14  5  5  5 22 22  7  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2  3  8 12  9 13 14  3 29 12 16 15  5 15 15  2 15  5\n",
      " 14  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2  3  8 12  9 13 14 15 12 12 12 15 15 15  7  7  7  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6  7  2 15  4 12  5 13  7  7  2 12 23 22 15 29  6 14  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 15  4 12  5 13  7 27  2 12  7 23 23 23 23 15  5 14  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1540\n",
      "  minibatch loss: 0.9145547747612\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8  9  6  7  2 16  8  5  6  7  7  8 10 25 14 20  2 22  8 27  8 14 23\n",
      " 22 15 29 14]\n",
      "    predicted > [ 2  3  8  9  6  7  2 16  8  5  6  7  8  8  8  2  8 14  2  2  8 14 25 22 22\n",
      " 22 28 14  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  4  5  6 14  2  3  8 12  5 13 14 22 19 15 21 22 15 19  6 11 14  0  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  5  4  5  6 14  2  3  8 12  5 13 14 22 22 22 22 22 15 15 15 19  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6 14  2 15  8 12  5 13 14 20  8 10 10 25  2  2  7 15  2 31  0\n",
      "  0  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6 14  2 15  8 12  5 13 14 20 10 10  2  2  2  2  2  6 23  7  7\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1560\n",
      "  minibatch loss: 0.7339513301849365\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13  7  2 12 13 14 11  6 19 20 19 25 15 19 15 19 14  0  0  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2 12 13 14 11 20 19 19 19 19 19 19  7  7  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 20  2  3  8 12  9 13  7 32 13  6 15 19 15 19  6  7 17  0  0  0  0  0  0]\n",
      "    predicted > [ 2 20  2  3  8 12  9 13  7 14 11  6  3 19 15 15 15 19 15 19 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4 12  5 13  7  2  3  8 12  9 13 14 12 21  3 25 16 15 10 19 15 19 14]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2  3  8 12  9 13 14 21 10 25 16 16 15 15 19  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1580\n",
      "  minibatch loss: 0.797906756401062\n",
      "  sample 1:\n",
      "    input     > [ 2  6 14 11  2 12 13  7 11  8  7 11 25  6 19 31  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  6 14 11  2 12 13  7 11 11  7  6  6  6 11 15 15 14  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  8  5  6  7  2 15  8  5  6  7 31 19  3 14  5 26  2 10 10 25 29 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2 16  8  5  6  7  2 15  8  5  6  7 31 19  3  6  5  5  5 15 15  6  6 23  6\n",
      " 14  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 16  4 12  5 13  7  2 10 10 25 16  6 19 25 25 19 15 19 14  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 16  4 12  5 13  7  2 10 25 25 25 16 19 19 18 17  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1600\n",
      "  minibatch loss: 0.879215657711029\n",
      "  sample 1:\n",
      "    input     > [ 2 15  8 12  5 13 14  2  6 14 11 14  5  6 27  8 12 31 23 22  6 23  7  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  8 12  5 13 14  2  6 14 11 14 11 27  8 14  8  6 23 22  6  6 31  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13 14  2 16  4  5  6 14 32  5 12  5 15 20 23 22  5  7  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2 16  4  5  6 14 14  5 26  5 15  5 22 22 29 14 14  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 23 14 17 37  7 20 23  6 14  5 10 15  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [17 23 14 17 23 14  7 15 23 14  5  6  2  2  1  1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1620\n",
      "  minibatch loss: 0.8225592970848083\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  9 13 14  2 10 28 19 22 14 11 26 19 25 15 11 22  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4 12  9 13 14  2 10 27 11 22 14 22 19 25 19 19 19  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4  5  6  7  2 12 13  7 11 19 22  2  7 29  6 14  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2 12 13  7 11 22 22  2  7  6 15 15  5 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  9  6  7  2 15  8  5  6  7 20  5  6 25  5 15 15 29  6 14  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 15  8  5  6  7 20  5 25  5 25  6  6  6  6 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1640\n",
      "  minibatch loss: 0.7959481477737427\n",
      "  sample 1:\n",
      "    input     > [ 2 16  4  5  6  7  2  3  4 12  5 13 14 12 19  7 29 14 23 22 28 29  6 14  0\n",
      "  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2  3  4 12  5 13 14 27  5 12 12 12 23 22 22 22  1  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  5 13 14  2 12 13 14 11 19 22 14 11 10 25 16 15 19 10 25  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2 12 13 14 11 27 19 11 25 19 25 25 25 15 19 19 19  1\n",
      "  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4  5  6 14  2  3  4  9  6 14 12 19 31 11 22  6 11 14  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  4  5  6 14  2  3  4  9  6 14 31 19 12 31 19 15 15 19  1  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1660\n",
      "  minibatch loss: 0.873217761516571\n",
      "  sample 1:\n",
      "    input     > [ 2  6  7 11  2  3  4 12  9 13  7 19 22 27  5 28 15  2  6 29  6 14  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2  6  7 11  2  3  4 12  9 13  7 27 22 22 15 15 15 15 15  5  5  5 14  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  9 13  7  2  3  4 12  9 13 14 20  8 25 10  3 23 22 15  2 15  5\n",
      " 14  0]\n",
      "    predicted > [ 2  3  4 12  9 13  7  2  3  4 12  9 13 14 10 10  8  8 15 23 22 15  2  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8 12  5 13  7  2 20 14 16  6 23 22  6 23 15  5 14  0  0  0  0  0  0\n",
      "  0  0]\n",
      "    predicted > [ 2 15  8 12  5 13  7  2 10 14 14  2  2  2  6  6  7  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1680\n",
      "  minibatch loss: 0.893204391002655\n",
      "  sample 1:\n",
      "    input     > [ 2  5  2  3  8 12  5 13 14 12  2  7 16 12  5 25 30  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  5  2  3  8 12  5 13 14 12 12 12 12 16 16  5  5  5  5  1  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  5 13 14  2  3  4 12  5 13  7 28 19 22 21 22 21  7  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  5 13 14  2  3  4 12  5 13  7 27 22 22 21 22 22 15 19 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  8 12  9 13  7  2 16  4  5  6  7 25  5 14  5  3 15 23 15  5 14  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  8 12  9 13  7  2 16  4  5  6  7 18  5  5  5  5 28 29 14 14  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1700\n",
      "  minibatch loss: 0.8683615922927856\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  5  6  7  2  6 14 11 19 22 12  5  6 15 29  6 14  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2  6 14 11 19 22  6  6  5  6  6  6 31  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [17 40  7 17 18  7  2  6  3  5 22  5 14 14  2 22  0  0  0  0  0  0  0  0  0\n",
      "  0]\n",
      "    predicted > [17 40  7 17 32  7  2  2  6  5 22  6  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  4 12  5 13 14  2 11 20 11  3  8  3 32 19 10 25 11 22  6 11 22  0  0\n",
      "  0]\n",
      "    predicted > [ 2 15  4 12  5 13 14  2 20 11 11  3  8  3  8  8  8  8  8 22  6  8  1  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1720\n",
      "  minibatch loss: 0.7032628059387207\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  9 13 14  2  9 15 11 12 16 15 19 15 15 19  7  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2  9 15 15 15 19 15 15 15 15  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  4  5  6  7  2  3  4 12  9 13  7 29  3 12  2 10 10 29  6 14  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2  3  4 12  9 13  7 15  2 12 12 15 15 15 15 15 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  6 14 11  2  3  4  5  6 14 19 22 20 19 12  6 19 31  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  6 14 11  2  3  4  5  6 14 19 19 19 19 19 14 14  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1740\n",
      "  minibatch loss: 0.8047441840171814\n",
      "  sample 1:\n",
      "    input     > [ 2  9  2  3  4  9  6 14 15  2  6 16 15 15  2 15  5 15 15  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  9  2  3  4  9  6 14 15  2  6  4 15 16 15 15 15 15 31  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 12 13  7 11  2  3  4  5  6  7 10 25  5 26 15  2 15  6  5 15  5 14  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 12 13  7 11  2  3  4  5  6  7 10  5 10  5 15 15 15 29 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13  7 11  2 16  8  5  6  7 14  8 25 10 23 14 31 23  6  4  5 22  6  5\n",
      " 15  5 14]\n",
      "    predicted > [ 2 12 13  7 11  2 16  8  5  6  7 10 25 23 14 23 14 23 23 23  4 25 25 29 14\n",
      " 14  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1760\n",
      "  minibatch loss: 0.8625075221061707\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4 12  5 13 14  2  3  4 12  9 13  7 31 19  3 18 16 20 10 25  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2  3  4 12  9 13  7 31 19  3 16 16 15 15 15 15 15 14\n",
      " 14  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  5 13  7  2 12 13 14 11 32 22  2  6 10 16 12  5 25 15  5 14]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2 12 13 14 11 32 19 22  2  6 16 16  5  6  6  5  5  1\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 23 14 17 18  7 18  5 25  5 31 23  6  4 15  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [17 23 14 17 18  7 23  5  6  5  6  5  6 15 14 14  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1780\n",
      "  minibatch loss: 0.8212774991989136\n",
      "  sample 1:\n",
      "    input     > [ 2 16  4  5  6  7  2 15  4  5  6  7 28  2 20 16 15 10 29  6 14  0  0]\n",
      "    predicted > [ 2 16  4  5  6  7  2 15  4  5  6  7 20  2 20 16 15 15  2  6  6 14  1  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [17 31 14 17 18  7  5 10 25 15 23 22  4 29  6 14  0  0  0  0  0  0  0]\n",
      "    predicted > [17 25 14 17 30  7 25  5  5 31 23  5 22 23 22 14  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6  7  2 10 27  5 22  4 15  2 15 29  6 14  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6  7  2 11 27 22  4  4 16  2 15 15  2  1  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1800\n",
      "  minibatch loss: 0.695354163646698\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  5 13  7  2 16  8 12  5 13  7 27 19 22 15 19 10 25  8 15 19 14]\n",
      "    predicted > [ 2  3  8 12  5 13  7  2 16  8 12  5 13  7 19 22 19 22 20 19 25 19 15 15 19\n",
      " 14  1  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 15  8 12  5 13 14  2  6  7 11 14 21 26  6 11  7  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2 15  8 12  5 13 14  2  6 14 11  7 21 21  6  6  6  1  1  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4  5  6 14  2 15  8 12  5 13  7 27 19 22 19  7 19 14  0  0  0  0  0]\n",
      "    predicted > [ 2  3  4  5  6 14  2 15  8 12  5 13  7 27 19 22 19 22  6 11 15 19 14  1  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1820\n",
      "  minibatch loss: 0.8031979203224182\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  9  6  7  2 16  4  5  6  7 31 19  3 21 22 15 13  6 14  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  3  4  9  6  7  2 16  4  5  6  7 31 19  3 19 22 22  6  6 14  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  6 14 11  2 16  8  5  6  7 22 19  8  3 23 25  6  5 31  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  6 14 11  2 16  8  5  6  7 22 19  8 22 22 22 28 29 14  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 12 13  7 11  2 15  8 12  5 13  7 15 23 12  3  4  8  2 10 16 15  2  6  5\n",
      " 15  5 14]\n",
      "    predicted > [ 2 12 13  7 11  2 15  8 12  5 13  7 23 23 12  3  2 10 10 16 15 15  6 23 15\n",
      "  5 14  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1840\n",
      "  minibatch loss: 0.8312410116195679\n",
      "  sample 1:\n",
      "    input     > [ 2  3  8 12  9 13  7  2 16  4 12  5 13  7 15  2 12 15 30 25 15  2 15 15 23\n",
      " 15  5 14]\n",
      "    predicted > [ 2  3  8 12  9 13  7  2 16  4 12  5 13  7 15  2 15 15 12 15 15 15 15 15  5\n",
      " 14 14  1  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2 16  8  5  6  7  2 20 15 19  6  4 11 10 10 25 13 14  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2 16  8  5  6  7  2 20 15 11 15  6  6 19 15 19  6  6  1  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [17 35  7 17 32  7 32  8 25  5  6  4 16 15 11 14  5 14 29 22  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [17 28  7 17 32  7 32  5  6  6  4 16 16  5 14 14 14  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1860\n",
      "  minibatch loss: 0.7967982292175293\n",
      "  sample 1:\n",
      "    input     > [ 2  6  7 11  2  3  4 12  5 13 14 15 23  6  9  5 22  6 29  6 14  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  6  7 11  2  3  4 12  5 13 14 15 23  5  5  5 22 22 22  1  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  5  2  3  4  9  6 14 32 19  8  7 11 25 17  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0]\n",
      "    predicted > [ 2  5  2  3  4  9  6 14 32 11 32 19 19 19 15 19  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  3  4 12  5 13 14  2  3  4 12  9 13  7 14  5 31 26 12  5 31  8 15 15 23\n",
      " 22 10 25]\n",
      "    predicted > [ 2  3  4 12  5 13 14  2  3  4 12  9 13  7 14  5 31 31 31 31 31  8 15 25 25\n",
      " 15 15 15 15  5 14  1  0  0  0  0  0  0]\n",
      "\n",
      "batch 1880\n",
      "  minibatch loss: 0.7920370697975159\n",
      "  sample 1:\n",
      "    input     > [ 2  3  4  5  6 14  2 15  4 12  5 13  7 14  5  6 25 19 12 20 23 22  5 14]\n",
      "    predicted > [ 2  3  4  5  6 14  2 15  4 12  5 13 14 14  5  6  7 20  5 25 23 22  6 23  5\n",
      " 14  1  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  8 12  9 13 14  2 20 14  2  9  2  3 15  2  7  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  3  8 12  9 13 14  2 20  2  2  2  2 15  2  7  7  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2  9  2  3  8 12  5 13 14  3  4 24 28 15  5 15 15  0  0  0  0  0  0  0]\n",
      "    predicted > [ 2  9  2  3  8 12  5 13 14  3  4 24  3 15 15  7  1  1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "batch 1900\n",
      "  minibatch loss: 0.65744948387146\n",
      "  sample 1:\n",
      "    input     > [ 2  5  2 16  4  5  6 14 18 19 22  4 32 19  6 18  2  3  4 30  0  0  0  0]\n",
      "    predicted > [ 2  5  2 16  4  5  6 14 18 19 18 19 18 18  6  4  4  4 25 25  2  6  1  1  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "  sample 2:\n",
      "    input     > [ 2  3  4 12  5 13  7  2  3  4  9  6  7  2 14  2 12 15  5 14  0  0  0  0]\n",
      "    predicted > [ 2  3  4 12  5 13  7  2  3  4  9  6 14  2  2  7 15 15 15 14  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "  sample 3:\n",
      "    input     > [ 2 15  8 12  5 13  7  2 11 20  8 22 23  3 16 15  2  6 23 15  5 14  0  0]\n",
      "    predicted > [ 2 15  8 12  5 13  7  2 11  8  8  3  3  2 15  2  6  6  6  7  1  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "\n",
    "try:\n",
    "    # get every batches and train the model on it\n",
    "    for batch_num in range(0, len(source_batches)):\n",
    "        fd = next_feed(batch_num, source_batches, target_batches)\n",
    "   \n",
    "        _, l = sess.run([train_op, loss], fd)\n",
    "        loss_track.append(l)\n",
    "        \n",
    "        if batch_num == 0 or batch_num % batches_in_epoch == 0:\n",
    "            print('batch {}'.format(batch_num))\n",
    "            print('  minibatch loss: {}'.format(sess.run(loss, fd)))\n",
    "            predict_ = sess.run(decoder_prediction, fd)\n",
    "            for i, (inp, pred) in enumerate(zip(fd[encoder_inputs].T, predict_.T)):\n",
    "                print('  sample {}:'.format(i + 1))\n",
    "                print('    input     > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 2:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
